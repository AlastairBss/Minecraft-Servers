{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe0qRHRdcL1GBAZSZHU8rZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlastairBss/Minecraft-Servers/blob/main/Copy_of_Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **k-Nearest Neighbour (KNN)**"
      ],
      "metadata": {
        "id": "Uo_MAxOlIVhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "names = iris.target_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "print(\"=== Prediction Results ===\")\n",
        "for actual, pred in zip(y_test, predictions):\n",
        "    if actual == pred:\n",
        "        print(f\"✅ Correct: {names[pred]}\")\n",
        "    else:\n",
        "        print(f\"❌ Wrong: Predicted {names[pred]}, Actual {names[actual]}\")\n",
        "\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXg0dL1q8pnZ",
        "outputId": "b308f604-4d19-485a-da7d-86a7964b007d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prediction Results ===\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: setosa\n",
            "✅ Correct: virginica\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: setosa\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: virginica\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: virginica\n",
            "✅ Correct: setosa\n",
            "✅ Correct: setosa\n",
            "✅ Correct: setosa\n",
            "✅ Correct: setosa\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: virginica\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: versicolor\n",
            "✅ Correct: virginica\n",
            "✅ Correct: setosa\n",
            "✅ Correct: virginica\n",
            "✅ Correct: setosa\n",
            "✅ Correct: virginica\n",
            "✅ Correct: virginica\n",
            "✅ Correct: virginica\n",
            "✅ Correct: virginica\n",
            "✅ Correct: virginica\n",
            "✅ Correct: setosa\n",
            "✅ Correct: setosa\n",
            "\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ARTIFICIAL NEURAL NETWORK (ANN)**"
      ],
      "metadata": {
        "id": "ywA9j2HjIH15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(5, 3), max_iter=1000, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoXYb84c_7O5",
        "outputId": "e2643cb1-5d3c-4822-c4a3-c8f6450ffd14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.11 %\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.69      0.82        13\n",
            "           2       0.76      1.00      0.87        13\n",
            "\n",
            "    accuracy                           0.91        45\n",
            "   macro avg       0.92      0.90      0.89        45\n",
            "weighted avg       0.93      0.91      0.91        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CANDIDATE**"
      ],
      "metadata": {
        "id": "L2iSq_zkJWT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "def more_general(h1, h2):\n",
        "    return all(x == '?' or (x == y) for x, y in zip(h1, h2))\n",
        "\n",
        "def fulfills(hypothesis, example):\n",
        "    return all(h == '?' or h == e for h, e in zip(hypothesis, example))\n",
        "\n",
        "def min_generalizations(h, x):\n",
        "    new_h = list(h)\n",
        "    for i in range(len(h)):\n",
        "        if h[i] != x[i]:\n",
        "            new_h[i] = '?'\n",
        "    return [new_h]\n",
        "\n",
        "def min_specializations(h, domains, x):\n",
        "    results = []\n",
        "    for i in range(len(h)):\n",
        "        if h[i] == '?':\n",
        "            for val in domains[i]:\n",
        "                if val != x[i]:\n",
        "                    new_h = h.copy()\n",
        "                    new_h[i] = val\n",
        "                    results.append(new_h)\n",
        "        elif h[i] != x[i]:\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "    return results\n",
        "\n",
        "def candidate_elimination(data):\n",
        "    attributes = data.columns[:-1]\n",
        "    domains = [list(data[attr].unique()) for attr in attributes]\n",
        "    num_attributes = len(attributes)\n",
        "    G = [['?'] * num_attributes]\n",
        "    S = None\n",
        "\n",
        "    for idx, row in data.iterrows():\n",
        "        if row.iloc[-1] == 'Yes':\n",
        "            S = [list(row[:-1])]\n",
        "            break\n",
        "\n",
        "    if S is None:\n",
        "        S = [['∅ '] * num_attributes]\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        example = list(row[:-1])\n",
        "        label = row.iloc[-1]\n",
        "\n",
        "        if label == 'Yes':\n",
        "            G = [g for g in G if fulfills(g, example)]\n",
        "            S_new = []\n",
        "            for s in S:\n",
        "                if fulfills(s, example):\n",
        "                    S_new.append(s)\n",
        "                else:\n",
        "                    generalized = min_generalizations(s, example)\n",
        "                    generalized = [h for h in generalized if any(more_general(g, h) for g in G)]\n",
        "                    S_new.extend(generalized)\n",
        "\n",
        "            S = []\n",
        "            for hyp in S_new:\n",
        "                if not any(more_general(hyp2, hyp) for hyp2 in S):\n",
        "                    S = [h for h in S if not more_general(h, hyp)]\n",
        "                    S.append(hyp)\n",
        "\n",
        "        else:\n",
        "            S = [s for s in S if not fulfills(s, example)]\n",
        "            G_new = []\n",
        "            for g in G:\n",
        "                if fulfills(g, example):\n",
        "                    specialized = min_specializations(g, domains, example)\n",
        "                    specialized = [h for h in specialized if any(more_general(h, s) for s in S)]\n",
        "                    G_new.extend(specialized)\n",
        "                else:\n",
        "                    G_new.append(g)\n",
        "\n",
        "            G = []\n",
        "            for hyp in G_new:\n",
        "                if not any(more_general(hyp, hyp2) for hyp2 in G):\n",
        "                    G = [h for h in G if not more_general(h, hyp)]\n",
        "                    G.append(hyp)\n",
        "\n",
        "    return S, G\n",
        "\n",
        "def main():\n",
        "    file_path = input(\"Enter the path of your CSV file: \")\n",
        "    try:\n",
        "        data = load_data(file_path)\n",
        "        S, G = candidate_elimination(data)\n",
        "        print(\"\\nFinal Specific Hypotheses (S):\")\n",
        "        for s in S:\n",
        "            print(s)\n",
        "        print(\"\\nFinal General Hypotheses (G):\")\n",
        "        for g in G:\n",
        "            print(g)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45gjgPEAI7ng",
        "outputId": "f043175e-6fee-46e1-c390-4f69770b2bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path of your CSV file: /content/candidate.csv\n",
            "\n",
            "Final Specific Hypotheses (S):\n",
            "['Sunny', 'Warm', '?', 'Strong', '?', '?']\n",
            "\n",
            "Final General Hypotheses (G):\n",
            "['Sunny', '?', '?', '?', '?', '?']\n",
            "['?', 'Warm', '?', '?', '?', '?']\n"
          ]
        }
      ]
    }
  ]
}